{
  "primitive-space": {
    "title": "SPACE",
    "section": "Triangle",
    "content": "Your CPU's L1 cache is 0.5ns away. RAM is 100ns. A datacenter across the ocean is 150ms. This 300,000x latency difference is why copies exist—you store data closer to avoid paying the distance tax repeatedly. Every cache line, every replica, every CDN edge node exists because physics makes distance expensive."
  },
  "primitive-time": {
    "title": "TIME",
    "section": "Triangle",
    "content": "A Rust `const` is known at compile time—before the program runs. A `let` binding is computed at runtime—when execution reaches that line. This distinction matters: compile-time values can be inlined, used for array sizes, and optimized away. Runtime values require actual memory and CPU cycles."
  },
  "primitive-identity": {
    "title": "IDENTITY",
    "section": "Triangle",
    "content": "When two variables point to the same memory, they share IDENTITY. Modify through one, the other sees it. In Rust, `let y = &x` creates shared identity. In C, `int *p = &x; int *q = &x;` does too. The question 'is this the same data or a copy?' determines whether you have a coherence obligation."
  },
  "primitive-state": {
    "title": "STATE",
    "section": "Triangle",
    "content": "STATE is not fundamental—it's derived from SPACE and TIME. The value at address 0x7fff at time T1 might be 42, at T2 might be 100. Mutation means STATE(space, t1) ≠ STATE(space, t2). Reading means observing STATE at a particular (SPACE, TIME) coordinate."
  },
  "layer-cpu-cache": {
    "title": "CPU Cache Layer",
    "section": "Layers",
    "content": "When Core 0 loads address X into L1, and Core 1 also loads X, there are now two copies. If Core 0 writes, the MESI protocol kicks in: Core 1's cache line is invalidated. This is hardware-level coherence—the CPU ensures both cores see consistent STATE despite having separate SPACEs."
  },
  "layer-compiler": {
    "title": "Compiler Layer",
    "section": "Layers",
    "content": "The compiler might keep `x` in a register for a hot loop instead of reading from RAM each iteration. That register is a derived copy. Register allocation is the compiler's coherence strategy—it tracks when the register must be written back to memory."
  },
  "layer-language": {
    "title": "Language Layer",
    "section": "Layers",
    "content": "In Rust, `let r1 = &data; let r2 = &data;` creates two references to the same SPACE. The borrow checker is the coherence strategy—it proves at compile time that no mutable reference coexists with these shared references."
  },
  "layer-thread": {
    "title": "Thread Layer",
    "section": "Layers",
    "content": "Thread A and Thread B both access a shared HashMap. Without synchronization, A's writes might not be visible to B, or worse, B sees a half-written state. A Mutex serializes access—only one thread touches the map at a time. Channels avoid sharing entirely by copying data between threads."
  },
  "layer-process": {
    "title": "Process Layer",
    "section": "Layers",
    "content": "Each process has its own address space—address 0x1000 in Process A is different from 0x1000 in Process B. Shared memory creates a region where they overlap. Without IPC coordination, both processes might corrupt the shared region."
  },
  "layer-database": {
    "title": "Database Layer",
    "section": "Layers",
    "content": "A write to the primary database must propagate to replicas. Synchronous replication waits until replicas confirm—strong consistency, high latency. Asynchronous replication returns immediately—low latency, but replicas may be stale. Same tradeoff, larger scale."
  },
  "layer-network": {
    "title": "Network Layer",
    "section": "Layers",
    "content": "A CDN caches your website at edge locations worldwide. When you update the origin, edge copies become stale. TTL says 'assume valid for N seconds.' Purge says 'invalidate now.' Both are sync strategies trading freshness against coordination cost."
  },
  "layer-geo": {
    "title": "Geo-distributed Layer",
    "section": "Layers",
    "content": "Users in Tokyo write to the Tokyo datacenter. Users in London write to London. Both datacenters have the 'same' database. Eventual consistency means Tokyo's write might not be visible in London for seconds or minutes. Strong consistency means every write waits for global consensus."
  },
  "remove-identity": {
    "title": "Remove Shared Identity",
    "section": "Coherence Problem",
    "content": "In Rust, `let y = x.clone()` creates an independent copy. Mutating `y` doesn't affect `x`. There's no shared identity, so no coherence problem. This is value semantics—each copy is its own entity. The cost: memory and CPU for the clone operation."
  },
  "remove-space": {
    "title": "Remove Multiple Spaces",
    "section": "Coherence Problem",
    "content": "If your database has no replicas—just one primary—there's only one SPACE for each row. No copies means no divergence. The cost: that single server is a bottleneck and a single point of failure. Same for a single-threaded program with no concurrent access."
  },
  "remove-time": {
    "title": "Remove Time Flows",
    "section": "Coherence Problem",
    "content": "In Haskell, values don't change after creation. You can share references freely across threads because nobody can mutate. The vector you passed to another thread will still be [1,2,3] tomorrow. Immutability eliminates coherence problems entirely—at the cost of requiring new allocations for 'updates.'"
  },
  "op-read": {
    "title": "Read Operation",
    "section": "Operations",
    "content": "Reading observes STATE at (SPACE, TIME). In Rust: `let val = *ptr;`. At the system level: SELECT from database, cache hit. The question is: which SPACE are you reading from, and is it current? A stale cache read gives you STATE at an earlier TIME."
  },
  "op-write": {
    "title": "Write Operation",
    "section": "Operations",
    "content": "Writing changes STATE at a SPACE. In Rust: `*ptr = 42;`. At the system level: UPDATE in database, write to primary. This creates the coherence obligation—if other SPACEs hold copies with the same IDENTITY, they're now stale."
  },
  "op-copy": {
    "title": "Copy Operation",
    "section": "Operations",
    "content": "Copying creates a new SPACE with the same value but independent IDENTITY. In Rust: `let y = x;` for Copy types, or `x.clone()`. After the copy, mutations to `x` don't affect `y`. You've traded memory for independence."
  },
  "op-move": {
    "title": "Move Operation",
    "section": "Operations",
    "content": "Moving transfers IDENTITY from one SPACE to another and invalidates the source. In Rust: `let y = x;` for non-Copy types makes `x` unusable. There's only ever one valid reference, so no coherence problem. The source SPACE is logically gone."
  },
  "op-alias": {
    "title": "Alias Operation",
    "section": "Operations",
    "content": "Aliasing creates a second path to the same SPACE. The alias has its own lifetime (existence TIME), which must be contained within the value's lifetime—if the value dies or moves while aliases exist, you get dangling references. Rust's borrow checker enforces both: aliases cannot outlive their referent (existence coherence), and mutable aliases cannot coexist with other aliases (parallel coherence)."
  },
  "op-sync": {
    "title": "Sync Operation",
    "section": "Operations",
    "content": "Syncing reconciles divergent copies. For databases: replication. For CPU caches: MESI protocol. For threads: releasing a mutex flushes writes, acquiring it loads fresh data. The sync operation is where you pay the coherence cost you've deferred."
  },
  "sync-forbid": {
    "title": "Forbid the Problem",
    "section": "Sync Strategies",
    "content": "Rust's ownership model: each value has exactly one owner. `let y = x;` moves ownership—`x` is gone. You can't have two mutable paths to the same data because the type system forbids it. No aliasing + mutation means no coherence problem to solve."
  },
  "sync-freeze": {
    "title": "Freeze Time",
    "section": "Sync Strategies",
    "content": "Clojure's persistent vectors: when you 'update' index 5, you get a new vector sharing structure with the old one. The original never changes. Any thread holding the old reference sees consistent data forever. Erlang does the same with process state."
  },
  "sync-serialize": {
    "title": "Serialize Access",
    "section": "Sync Strategies",
    "content": "A Mutex ensures only one thread accesses data at a time. `mutex.lock()` blocks until you have exclusive access. This serializes TIME—concurrent execution becomes sequential for that critical section. Cost: threads wait, potential deadlocks."
  },
  "sync-hardware": {
    "title": "Hardware Arbitration",
    "section": "Sync Strategies",
    "content": "AtomicU64 uses CPU instructions like LOCK CMPXCHG. Multiple cores can attempt concurrent updates; the hardware arbitrates and ensures a total order. Compare-and-swap (CAS) loops let you build lock-free structures, but reasoning about them is notoriously difficult."
  },
  "sync-compile": {
    "title": "Compile-time Proof",
    "section": "Sync Strategies",
    "content": "Rust's borrow checker: you can have many `&T` OR one `&mut T`, never both. This is checked at compile time—zero runtime cost. The compiler proves your code has no data races before it ever runs. Invalid programs don't compile."
  },
  "sync-cow": {
    "title": "Copy-on-Write",
    "section": "Sync Strategies",
    "content": "Multiple readers share the same physical pages. When one writes, the OS copies that page first—only the writer pays. This defers the copy cost until mutation actually happens. Used in fork(), some filesystems, and Rust's Cow<T> type."
  },
  "sync-message": {
    "title": "Message Passing",
    "section": "Sync Strategies",
    "content": "Go channels and Erlang processes: instead of sharing memory, you send copies of data. The sender's version and receiver's version are independent after the send. No shared state means no synchronization needed—at the cost of serialization and copying."
  },
  "sync-optimistic": {
    "title": "Optimistic Concurrency",
    "section": "Sync Strategies",
    "content": "MVCC databases keep multiple versions. Readers see a snapshot; writers create new versions. Conflicts are detected at commit time—if someone else modified the row, your transaction aborts and retries. Optimistic that conflicts are rare."
  },
  "sync-trust": {
    "title": "Trust the User",
    "section": "Sync Strategies",
    "content": "C gives you raw pointers and says 'good luck.' Rust's `unsafe` blocks let you bypass the borrow checker when you need to. You're asserting the coherence is handled—by your own reasoning, external synchronization, or invariants the compiler can't see."
  },
  "lang-haskell": {
    "title": "Haskell",
    "section": "Language Choices",
    "content": "Values are immutable by default. A function can't modify its arguments—it returns new values. The IO monad sequences effects but doesn't allow mutation of pure values. Concurrent Haskell is straightforward because shared immutable data needs no synchronization."
  },
  "lang-erlang": {
    "title": "Erlang",
    "section": "Language Choices",
    "content": "Each process has isolated memory—no shared state by design. Communication happens via message passing, which copies data. If a process crashes, others are unaffected. This model scales to distributed systems naturally: same semantics whether processes are local or remote."
  },
  "lang-clojure": {
    "title": "Clojure",
    "section": "Language Choices",
    "content": "Persistent data structures share underlying storage but appear immutable. Refs provide coordinated synchronous updates via STM. Atoms provide uncoordinated synchronous updates. Agents provide asynchronous updates. Each is a different coherence strategy for different needs."
  },
  "lang-rust": {
    "title": "Rust",
    "section": "Language Choices",
    "content": "Ownership + borrowing at compile time. One mutable reference OR many immutable references—never both. Send and Sync traits track what's safe to share across threads. Data races are compile errors, not runtime bugs. Zero-cost abstractions: the checks happen at compile time."
  },
  "lang-go": {
    "title": "Go",
    "section": "Language Choices",
    "content": "Shares memory like C but provides channels for message passing. The mantra: 'Don't communicate by sharing memory; share memory by communicating.' But channels are optional—you can still use mutexes, or just share unsafely. The race detector helps but doesn't guarantee."
  },
  "lang-java": {
    "title": "Java",
    "section": "Language Choices",
    "content": "Object references are shared freely. `synchronized` blocks and `volatile` fields provide synchronization. The Java Memory Model specifies visibility guarantees. GC handles SPACE but not IDENTITY+TIME—you still need locks to prevent data races on shared mutable objects."
  },
  "lang-c": {
    "title": "C/C++",
    "section": "Language Choices",
    "content": "Pointers can alias anything. `const` is a promise, not enforcement—`const_cast` can remove it. C++11 added atomics and a memory model, but data races are still undefined behavior. The programmer is fully responsible for coherence."
  },
  "lang-js": {
    "title": "JavaScript",
    "section": "Language Choices",
    "content": "Single-threaded event loop: only one piece of code runs at a time. No concurrent mutation means no data races—by construction. Web Workers add parallelism but with isolated memory and message passing. SharedArrayBuffer brings back shared memory and the coherence problem."
  },
  "lang-python": {
    "title": "Python",
    "section": "Language Choices",
    "content": "The Global Interpreter Lock (GIL) ensures only one thread executes Python bytecode at a time. This serializes TIME at the interpreter level. True parallelism requires multiprocessing (separate memory spaces) or releasing the GIL in C extensions."
  },
  "construct-register": {
    "title": "Register",
    "section": "Language Constructs",
    "content": "The fastest SPACE—inside the CPU itself. The compiler decides what lives in registers. A hot loop counter stays in a register; the compiler writes it back to memory only when needed. You don't directly control this in most languages."
  },
  "construct-stack": {
    "title": "Stack Variable",
    "section": "Language Constructs",
    "content": "In Rust: `let x = 5;`. Lives on the stack, scoped to the block. When the block ends, the stack frame pops, and `x` is gone. No heap allocation, no GC. IDENTITY is unique within the scope—only local code can reference it."
  },
  "construct-heap": {
    "title": "Heap Allocation",
    "section": "Language Constructs",
    "content": "In Rust: `Box::new(5)` or `Vec::new()`. Lives on the heap, can outlive the creating scope if moved. Multiple references possible: `Rc<T>` for single-thread, `Arc<T>` for multi-thread. The coherence strategy depends on whether you use interior mutability."
  },
  "construct-const": {
    "title": "Compile-time Const",
    "section": "Language Constructs",
    "content": "In Rust: `const MAX: u32 = 100;`. The value is known at compile time and inlined at every use site. No address—each use is like copy-pasting the literal. Can be used for array sizes: `[0u8; MAX]`. Zero runtime cost."
  },
  "construct-static": {
    "title": "Static / Global",
    "section": "Language Constructs",
    "content": "In Rust: `static COUNTER: AtomicU32 = AtomicU32::new(0);`. One address, lives for the entire program in the data segment. Global IDENTITY—all code sees the same location. If mutable, you need atomics or unsafe to manage coherence."
  },
  "construct-tls": {
    "title": "Thread-local",
    "section": "Language Constructs",
    "content": "In Rust: `thread_local! { static X: Cell<u32> = Cell::new(0); }`. Each thread gets its own copy. No shared IDENTITY across threads, so no synchronization needed. Useful for per-thread caches or context that shouldn't be shared."
  },
  "construct-immutable": {
    "title": "Immutable Value",
    "section": "Language Constructs",
    "content": "In Rust: `let x = vec![1,2,3];` (without mut). You can share `&x` freely because no mutation is possible through those references. The compiler enforces this. Interior mutability (`Cell`, `RefCell`) opts out but brings its own rules."
  },
  "construct-locked": {
    "title": "Mutable + Locked",
    "section": "Language Constructs",
    "content": "In Rust: `Mutex<HashMap<K,V>>`. The Mutex serializes access—`lock()` gives you exclusive `&mut` to the inner data. While you hold the guard, no other thread can access it. Drop the guard to release. Deadlock is possible if you acquire multiple locks in inconsistent order."
  },
  "construct-atomic": {
    "title": "Atomic",
    "section": "Language Constructs",
    "content": "In Rust: `AtomicU64`. The CPU guarantees individual operations (load, store, compare_exchange) are indivisible. Memory ordering (SeqCst, Acquire, Release) controls visibility to other threads. Lock-free but subtle—most people should use Mutex instead."
  },
  "construct-channel": {
    "title": "Channel Message",
    "section": "Language Constructs",
    "content": "In Rust: `std::sync::mpsc::channel()`. Data is moved (not shared) from sender to receiver. The sender gives up ownership; the receiver gets it. No shared IDENTITY means no data race. FIFO ordering; blocks if buffer is full or empty."
  },
  "example-immutable": {
    "title": "Immutability Enables Safe Sharing",
    "section": "Examples",
    "content": "In Clojure, 10 threads can read the same vector simultaneously with no locks. In Rust, 10 threads can hold `&Vec<T>` with no synchronization. Because TIME is frozen (no mutation), shared IDENTITY is harmless. This is why functional programming and concurrency pair well."
  },
  "example-rust-concurrency": {
    "title": "Rust's Fearless Concurrency",
    "section": "Examples",
    "content": "The compiler rejects `let handle = thread::spawn(|| println!(\"{}\", local_var));` if `local_var` doesn't live long enough or isn't thread-safe. Send and Sync traits encode what can cross thread boundaries. Data races become type errors caught before your code runs."
  },
  "example-locks-slow": {
    "title": "Locks Are Slow",
    "section": "Examples",
    "content": "A mutex serializes TIME—threads that could run in parallel instead wait. With 8 threads and a hot lock, you might get *worse* performance than single-threaded because of contention and cache line bouncing. Fine-grained locking or lock-free structures help but add complexity."
  },
  "example-lockfree": {
    "title": "Lock-free Is Hard",
    "section": "Examples",
    "content": "A lock-free queue sounds simple: CAS to enqueue, CAS to dequeue. But what about ABA problems? Memory reclamation? Ensuring linearizability? The literature is full of 'obviously correct' lock-free algorithms that turned out to have subtle bugs years later."
  },
  "example-gc-races": {
    "title": "GC Doesn't Prevent Data Races",
    "section": "Examples",
    "content": "Java has GC but still needs synchronized blocks. GC handles SPACE (memory lifecycle) but not IDENTITY+TIME (who can access when). Two threads modifying an ArrayList concurrently corrupt it regardless of GC. You still need coherence strategy."
  },
  "example-js-single": {
    "title": "JavaScript Is Single-threaded",
    "section": "Examples",
    "content": "The event loop runs one callback at a time. Your click handler finishes completely before the next event fires. This serializes TIME globally—no concurrent mutation possible. It's limiting for CPU-bound work but eliminates a whole class of bugs."
  },
  "example-python-gil": {
    "title": "Python's GIL",
    "section": "Examples",
    "content": "Even with threading, only one thread executes Python bytecode at once. This serializes TIME at the interpreter level. For I/O-bound work, threads help (they release the GIL while waiting). For CPU-bound work, you need multiprocessing to get true parallelism."
  },
  "example-value-types": {
    "title": "Value Types Are Easier",
    "section": "Examples",
    "content": "In Swift and C#, structs are value types—assignment copies. Each copy is independent, new IDENTITY. No shared state means no coherence problem. The tradeoff: copying large structs is expensive. Reference types share by default and bring back the problem."
  },
  "example-pointers": {
    "title": "Pointers Are Dangerous",
    "section": "Examples",
    "content": "In C: `int *p = &x; int *q = &x; *p = 5;` Now q points to 5 too. With unrestricted aliasing (anyone can point anywhere) and free mutation (no compiler checks), coherence is entirely your problem. Add threads and it's undefined behavior."
  },
  "example-const-differs": {
    "title": "const Differs Across Languages",
    "section": "Examples",
    "content": "Rust `const`: compile-time, inlined. C/C++ `const`: 'I promise not to mutate through this path' (can be cast away). JavaScript `const`: 'this binding doesn't change' (object contents can). Same keyword, completely different positions in the SPACE/TIME/IDENTITY design space."
  },
  "hazard-read": {
    "title": "Read Hazard",
    "section": "Operations",
    "content": "When multiple TIME lines read shared SPACE, each may see different STATE. A read during a concurrent write may see a torn value—half old, half new. The question: which TIME's snapshot are you observing?"
  },
  "hazard-write": {
    "title": "Write Hazard",
    "section": "Operations",
    "content": "Two parallel writes to the same SPACE: one overwrites the other. Without ordering, you get lost updates. The granularity matters—two writes to different bytes in the same cache line still conflict (false sharing). Someone must arbitrate who wins."
  },
  "hazard-copy": {
    "title": "Copy Hazard",
    "section": "Operations",
    "content": "Copying reads the source. If another TIME line mutates the source mid-copy, you get a torn copy—part old state, part new. The copy is internally inconsistent, never representing any valid STATE."
  },
  "hazard-move": {
    "title": "Move Hazard",
    "section": "Operations",
    "content": "Move invalidates the source. Two parallel moves of the same value: both think they own it, both invalidate it. Use-after-move, double-free. Rust's ownership prevents this at compile time."
  },
  "hazard-alias": {
    "title": "Alias Hazard",
    "section": "Operations",
    "content": "Alias creates shared IDENTITY. Alias + mutation + parallel TIME = data race. This is THE coherence problem: multiple paths to the same SPACE, at least one writing, without synchronization. Every language must address this."
  },
  "hazard-sync": {
    "title": "Sync (Solution)",
    "section": "Operations",
    "content": "Sync is not a hazard—it's the solution. Explicitly reconciling divergent copies across TIME lines. The cost you pay to restore coherence after allowing parallel access."
  },
  "time-execution": {
    "title": "Execution TIME",
    "section": "Dimensions of TIME",
    "content": "Sequential ordering of operations. Statement A executes before statement B. Single-threaded programs have one execution TIME line—total ordering of all operations. This is the TIME most programmers think about."
  },
  "time-parallel": {
    "title": "Parallel TIME",
    "section": "Dimensions of TIME",
    "content": "Multiple execution TIME lines running simultaneously. Thread 1 and Thread 2 each have their own sequence, but operations across threads have no inherent order. This is where 'simultaneous' access becomes possible and coherence problems emerge."
  },
  "time-existence": {
    "title": "Existence TIME",
    "section": "Dimensions of TIME",
    "content": "How long does something exist? A stack variable lives until scope exit. A heap allocation lives until free. A reference has its own lifetime that must fit within the referent's lifetime. Rust's borrow checker tracks existence TIME to prevent dangling references."
  },
  "expr-variables": {
    "title": "Variables",
    "section": "Expression Layer",
    "content": "A variable is a name for SPACE. In `let x = 5`, 'x' is the name, and somewhere in memory (stack, heap, register) lives the value 5. The variable creates an IDENTITY relationship between the name and that SPACE. Different languages give different guarantees about how long this relationship holds."
  },
  "expr-scopes": {
    "title": "Scopes",
    "section": "Expression Layer",
    "content": "A scope is a bounded region of TIME. When you enter a block `{ }`, TIME begins for variables declared inside. When you exit, their TIME ends. In Rust, this triggers Drop. In C, the stack frame pops. Scopes let us reason locally: names inside can't leak outside."
  },
  "expr-functions": {
    "title": "Functions",
    "section": "Expression Layer",
    "content": "A function is a reusable sequence of TIME. Each call creates a new TIME context (stack frame). Parameters transfer IDENTITY into this context; return transfers IDENTITY out. Recursion is nested TIME. Closures capture IDENTITY across TIME boundaries."
  },
  "expr-types": {
    "title": "Types",
    "section": "Expression Layer",
    "content": "Types constrain what can inhabit a SPACE. An `i32` says: this SPACE holds 4 bytes interpreted as a signed integer. Types also guide IDENTITY: `Copy` types duplicate freely; non-Copy types move. Rust's `Send`/`Sync` constrain IDENTITY across parallel TIME."
  },
  "expr-references": {
    "title": "References",
    "section": "Expression Layer",
    "content": "A reference creates an IDENTITY relationship to existing SPACE without owning it. In Rust, `&x` says: I can read x's SPACE, but someone else owns it. The reference's validity (TIME) must not exceed the referent's. This is what lifetimes track."
  },
  "expr-threads": {
    "title": "Threads",
    "section": "Expression Layer",
    "content": "Threads introduce parallel TIME—multiple execution sequences happening simultaneously. This multiplies the interaction complexity: SPACE can now be accessed from multiple TIME lines at once. Without coordination, the order of accesses is undefined, creating race conditions."
  },
  "pair-space-time": {
    "title": "SPACE × TIME",
    "section": "Pairwise Interactions",
    "content": "When does memory exist? Stack SPACE exists for function TIME. Heap SPACE exists until explicitly freed (or GC collects). This interaction produces: allocation, deallocation, initialization, mutation, lifetime. Memory management is fundamentally about SPACE × TIME coordination."
  },
  "pair-space-identity": {
    "title": "SPACE × IDENTITY",
    "section": "Pairwise Interactions",
    "content": "How many paths lead to memory? One name for one location is simple. Multiple names (aliases) for one location creates complexity: modify through one, visible through all. This interaction produces: pointers, references, aliasing, copying, moving. Ownership systems are about controlling SPACE × IDENTITY."
  },
  "pair-time-identity": {
    "title": "TIME × IDENTITY",
    "section": "Pairwise Interactions",
    "content": "When is a name valid? A variable declared in a block is valid until block exit. A reference is valid while the referent exists. Shadowing creates new IDENTITY that hides old in TIME. This interaction produces: scope, shadowing, rebinding, closures, drop order."
  },
  "bug-memory-leak": {
    "title": "Memory Leak",
    "section": "Bugs",
    "content": "SPACE × TIME failure: memory allocated but never freed. The SPACE continues to exist past its useful TIME. In C: malloc without free. In reference-counted systems: cycles prevent count reaching zero. Not immediately catastrophic, but accumulates until SPACE exhaustion."
  },
  "bug-use-after-free": {
    "title": "Use-after-free",
    "section": "Bugs",
    "content": "SPACE × TIME × IDENTITY failure: SPACE is deallocated (TIME ends), but IDENTITY (pointer) still exists and is used. The SPACE may now hold different data or be unmapped. Classic source of security vulnerabilities—attacker can control what's read/written through stale pointer."
  },
  "bug-dangling-pointer": {
    "title": "Dangling Pointer",
    "section": "Bugs",
    "content": "TIME × IDENTITY failure: reference outlives its referent. In C: returning pointer to local variable. The IDENTITY survives function return, but SPACE is reclaimed. Accessing it reads garbage or crashes. Rust's borrow checker exists primarily to prevent this."
  },
  "bug-data-race": {
    "title": "Data Race",
    "section": "Bugs",
    "content": "SPACE × TIME × IDENTITY failure: two threads access same SPACE, at least one writes, no synchronization. The parallel TIME lines interleave unpredictably. Result: torn reads, lost updates, corrupted data. Rust prevents at compile time; most languages detect at runtime (if lucky)."
  },
  "bug-double-free": {
    "title": "Double Free",
    "section": "Bugs",
    "content": "SPACE × TIME failure: SPACE deallocated twice. First free: ok. Second free: allocator corruption or security vulnerability. Often caused by confused IDENTITY—two pointers think they own the same SPACE. Ownership systems (unique IDENTITY) prevent this by construction."
  },
  "bug-null-deref": {
    "title": "Null Dereference",
    "section": "Bugs",
    "content": "SPACE × IDENTITY failure: IDENTITY points to no SPACE. Dereferencing follows the IDENTITY relationship to... nothing. Immediate crash (if lucky) or undefined behavior. Nullable type systems (Option<T>, Maybe) make the 'no SPACE' case explicit and force handling."
  },
  "bug-buffer-overflow": {
    "title": "Buffer Overflow",
    "section": "Bugs",
    "content": "SPACE × IDENTITY failure: IDENTITY accesses beyond SPACE bounds. Array of 10 elements, you access index 15. You're now reading/writing adjacent SPACE you don't own. Classic attack vector: overwrite return address, execute arbitrary code. Bounds checking prevents this."
  },
  "bug-uninitialized": {
    "title": "Uninitialized Read",
    "section": "Bugs",
    "content": "SPACE × TIME × IDENTITY failure: IDENTITY used before SPACE has a value. The SPACE exists, the name exists, but no value was stored yet. You read whatever bits happened to be there. Rust requires initialization before use; C happily gives you garbage."
  },
  "feat-gc": {
    "title": "Garbage Collection",
    "section": "Features — SPACE × TIME",
    "content": "Runtime tracks which SPACE is reachable via any IDENTITY. When SPACE has no paths to it, deallocate. Programmer never explicitly manages SPACE × TIME—the collector does. Cost: unpredictable pauses, memory overhead. Benefit: no manual lifetime management, no use-after-free."
  },
  "feat-raii": {
    "title": "RAII",
    "section": "Features — SPACE × TIME",
    "content": "Resource Acquisition Is Initialization. SPACE lifetime tied to scope TIME. Constructor acquires SPACE; destructor releases. When scope ends, cleanup happens automatically. C++ destructors, Rust Drop trait. Deterministic, no GC pauses, but requires ownership discipline."
  },
  "feat-refcount": {
    "title": "Reference Counting",
    "section": "Features — SPACE × TIME",
    "content": "Track how many IDENTITYs point to SPACE. When count drops to zero, deallocate. Immediate reclamation (no GC pause), but cycles leak (A→B→A keeps both alive). Rc<T> in Rust (single-thread), Arc<T> (multi-thread). Weak references break cycles."
  },
  "feat-ownership": {
    "title": "Ownership",
    "section": "Features — SPACE × IDENTITY",
    "content": "Unique IDENTITY to SPACE. Exactly one owner at a time. Transfer (move) is explicit, invalidates source. No aliasing by default means no confusion about who deallocates. Rust's core innovation: ownership at compile time, zero runtime cost."
  },
  "feat-move-semantics": {
    "title": "Move Semantics",
    "section": "Features — SPACE × IDENTITY",
    "content": "Transfer IDENTITY from source to destination. Source becomes invalid (Rust) or empty (C++). Avoids copies for large data: just transfer the IDENTITY. In Rust, non-Copy types move by default. In C++, std::move requests a move (but doesn't enforce invalidation)."
  },
  "feat-value-types": {
    "title": "Value Types",
    "section": "Features — SPACE × IDENTITY",
    "content": "Assignment copies, creating new SPACE with new IDENTITY. No aliasing—each copy is independent. Simple to reason about but expensive for large data. Rust's Copy trait marks types that are cheap to copy (integers, small structs). Swift/C# distinguish struct (value) from class (reference)."
  },
  "feat-lexical-scope": {
    "title": "Lexical Scope",
    "section": "Features — TIME × IDENTITY",
    "content": "IDENTITY valid within textual boundaries. A variable declared in a block is visible only inside that block's TIME. Enables local reasoning: names can't leak. Most languages use lexical scope. Alternative (dynamic scope) makes IDENTITY depend on call TIME, harder to reason about."
  },
  "feat-lifetimes": {
    "title": "Lifetimes",
    "section": "Features — TIME × IDENTITY",
    "content": "Explicit bounds on IDENTITY validity. In Rust, `&'a T` says: this reference is valid for TIME span 'a. The compiler checks that 'a doesn't exceed the referent's TIME. Makes TIME × IDENTITY relationship explicit and verifiable. The key to Rust's safety without GC."
  },
  "feat-closures": {
    "title": "Closures",
    "section": "Features — TIME × IDENTITY",
    "content": "Functions that capture IDENTITY from enclosing scope. The captured variables' IDENTITY extends across TIME boundaries—beyond the original scope. How to capture? By reference (borrow), by move (take ownership), by copy? Different languages make different choices. Rust lets you choose."
  },
  "feat-borrow-checker": {
    "title": "Borrow Checker",
    "section": "Features — SPACE × TIME × IDENTITY",
    "content": "Compile-time proof that SPACE × TIME × IDENTITY are consistent. No dangling (IDENTITY within SPACE's TIME). No races (no shared mutable IDENTITY in parallel TIME). Analyzes all three dimensions simultaneously. The algorithm: dataflow analysis + constraint solving + conflict detection."
  },
  "feat-mutex": {
    "title": "Locks / Mutex",
    "section": "Features — SPACE × TIME × IDENTITY",
    "content": "Serialize parallel TIME. Multiple threads want SPACE access; mutex ensures only one at a time. TIME becomes sequential at the lock boundary. Safe but slow: threads wait. Deadlock possible if multiple locks acquired inconsistently. Rust's Mutex<T> ties data to lock—can't access without locking."
  },
  "feat-atomics": {
    "title": "Atomics",
    "section": "Features — SPACE × TIME × IDENTITY",
    "content": "Hardware-arbitrated SPACE × TIME. CPU guarantees individual operations are indivisible. Multiple threads can access, hardware ensures total order. Faster than locks (no blocking) but limited to simple operations. Memory ordering (SeqCst, Acquire, Release) controls visibility across TIME."
  },
  "feat-channels": {
    "title": "Channels",
    "section": "Features — SPACE × TIME × IDENTITY",
    "content": "Transfer IDENTITY across threads, no shared SPACE. Sender gives up ownership; receiver gets it. No simultaneous access, no races by construction. Message passing instead of shared memory. Cost: copying/serialization. Go channels, Rust mpsc, Erlang messages."
  },
  "feat-immutability": {
    "title": "Immutability",
    "section": "Features — SPACE × TIME × IDENTITY",
    "content": "Freeze the TIME dimension: no mutation. If SPACE never changes, parallel access is safe—all TIME lines see the same STATE. Sharing IDENTITY freely because no writes to conflict. Haskell's default, Clojure's persistent structures, Rust's non-mut bindings."
  },
  "feat-actors": {
    "title": "Actor Model",
    "section": "Features — SPACE × TIME × IDENTITY",
    "content": "Isolate SPACE per actor. Each actor owns its SPACE exclusively. Communication only through messages (IDENTITY transfer, not sharing). If an actor crashes, others are unaffected—SPACE isolation contains failure. Erlang/OTP, Akka. Scales naturally to distributed systems."
  },
  "feat-linear-types": {
    "title": "Linear Types",
    "section": "Features — SPACE × TIME × IDENTITY",
    "content": "IDENTITY must be used exactly once. Can't ignore (must use), can't duplicate (must not alias). Ensures resources are properly handled: file handles closed, memory freed. Rust's ownership is almost linear (can move, but not copy non-Copy). Full linear types in Clean, experimental in Haskell."
  },
  "paradigm-functional": {
    "title": "Functional Paradigm",
    "section": "Paradigms",
    "content": "Freeze TIME: values don't change. Functions return new values instead of mutating. No mutable state means no state-related bugs. Sharing is safe (immutable IDENTITY). Cost: allocations for 'updates'. Enables: equational reasoning, trivial concurrency. Haskell, Clojure, Elm."
  },
  "paradigm-oop": {
    "title": "OOP Paradigm",
    "section": "Paradigms",
    "content": "Encapsulate SPACE: hide memory behind interfaces. Objects own SPACE, expose methods. Internal representation can change without affecting users. Aliasing still possible (multiple refs to object). Coherence is programmer's problem. Benefit: modularity. Java, C++, Python."
  },
  "paradigm-rust": {
    "title": "Rust's Approach",
    "section": "Paradigms",
    "content": "Constrain IDENTITY: ownership + borrowing. Unique ownership prevents aliasing ambiguity. Borrowing allows temporary shared IDENTITY with rules. Compiler verifies all three dimensions at compile time. Cost: learning curve, fighting the borrow checker. Gain: safety + performance."
  },
  "paradigm-actor": {
    "title": "Actor Paradigm",
    "section": "Paradigms",
    "content": "Isolate SPACE: no sharing between actors. Each actor is a SPACE island with its own TIME line. Communication via messages only. Failures are contained. Scales to distributed systems naturally—same model whether actors are local or remote. Erlang, Elixir, Akka."
  },
  "paradigm-linear": {
    "title": "Linear Paradigm",
    "section": "Paradigms",
    "content": "Constrain IDENTITY: use exactly once. Resources can't be forgotten (must use) or duplicated (no aliasing). Perfect for modeling real-world resources: file handles, network connections, unique tokens. Strict discipline, but guarantees resource safety. Clean, some Rust patterns."
  },
  "constraint-forward-time": {
    "title": "Forward-only TIME",
    "section": "Representation Constraints",
    "content": "Execution proceeds forward; statements can't be undone. You can't 'go back' to a previous state. This is fundamental to how computers execute: instruction pointer moves forward. Loops aren't time travel—they're forward repetition. Recursion unwinds forward. TIME only flows one way."
  },
  "constraint-names-persist": {
    "title": "Names Persist",
    "section": "Representation Constraints",
    "content": "Once a name is declared, it exists until scope ends. You can't 'undeclare' a variable mid-scope. The name→IDENTITY mapping persists. Shadowing doesn't delete—it overlays. The old binding may still run its destructor at scope end. Names are permanent within their scope."
  },
  "constraint-values-persist": {
    "title": "Values Persist",
    "section": "Representation Constraints",
    "content": "A value exists until its scope ends; you can't delete it mid-scope. Move semantics work around this: transfer IDENTITY, mark source invalid. But the name still exists, the stack slot still exists. Deletion is simulated, not actual."
  },
  "constraint-stack-lifo": {
    "title": "Stack is LIFO",
    "section": "Representation Constraints",
    "content": "Stack frames must be deallocated in reverse order of creation. Can't free the middle frame while outer frames exist. This is why heap exists: escape from LIFO discipline. Heap allows independent lifetimes at the cost of complexity (fragmentation, GC, manual management)."
  },
  "constraint-sequential-text": {
    "title": "Text is Sequential",
    "section": "Representation Constraints",
    "content": "Source code is written line by line, statement by statement. Parallelism must be explicitly expressed (threads, async, par-map) because the default representation is sequential. Dataflow languages escape this by expressing dependencies, not sequences."
  },
  "workaround-shadowing": {
    "title": "Shadowing",
    "section": "Representation Workarounds",
    "content": "Can't delete a name? Create a new binding with the same name. The old binding is hidden (shadowed), not deleted. Memory may still be allocated. Destructors run at scope end, not shadow point. Shadowing is 'poor man's deletion'—overlay instead of remove."
  },
  "workaround-move": {
    "title": "Move + Invalidation",
    "section": "Representation Workarounds",
    "content": "Can't delete a value mid-scope? Transfer its IDENTITY to another name and mark the source invalid. The compiler tracks four states: name exists (syntax), value exists (semantics), can use (valid), can shadow (name available). Move simulates deletion by severing IDENTITY."
  },
  "workaround-heap": {
    "title": "Heap Allocation",
    "section": "Representation Workarounds",
    "content": "Can't free mid-stack? Allocate on heap instead. Heap allows independent lifetimes: free `b` while `a` and `c` still exist. Cost: allocation overhead, fragmentation, explicit or GC management. Heap exists because stack's LIFO constraint is too restrictive."
  },
  "workaround-loops": {
    "title": "Loops",
    "section": "Representation Workarounds",
    "content": "Can't rewind TIME? Repeat forward instead. Loops execute the body multiple times, moving forward through TIME. Recursion is similar: call stack grows forward, then unwinds. Every repetition construct is forward-only because TIME is."
  },
  "workaround-immutability": {
    "title": "Immutability",
    "section": "Representation Workarounds",
    "content": "Can't undo mutation? Never mutate. Create new values instead of modifying old ones. Persistent data structures make this efficient by sharing unchanged parts. If you might need the old value, don't destroy it. Immutability sidesteps the forward-only problem."
  },
  "ssa-insight": {
    "title": "SSA Insight",
    "section": "Representation Constraints",
    "content": "Static Single Assignment reveals the truth: we never 'modified' a variable. Each assignment creates a new value with a new name (x1, x2, x3). 'Mutation' in source code is really name rebinding. The constraints were always there—SSA makes them explicit."
  },
  "rep-stack-based": {
    "title": "Stack-based Languages",
    "section": "Alternative Representations",
    "content": "Forth, PostScript: no variable names, only stack positions. `5 3 +` pushes 5, pushes 3, adds. Different constraint: must manage stack explicitly. Workaround: stack shuffling words (dup, swap, rot, drop). Names avoided entirely, replaced by position."
  },
  "rep-dataflow": {
    "title": "Dataflow Languages",
    "section": "Alternative Representations",
    "content": "TensorFlow, Apache Beam: nodes are operations, edges are data. No sequential TIME—operations run when inputs ready. Parallelism is natural, not explicit. Different constraint: must define whole graph upfront. Workaround: control dependencies, dynamic graphs."
  },
  "rep-logic": {
    "title": "Logic Languages",
    "section": "Alternative Representations",
    "content": "Prolog: declare relationships, not steps. `grandparent(X,Z) :- parent(X,Y), parent(Y,Z)`. Query, don't execute. No explicit TIME ordering in the logic. Different constraint: less imperative control. Workaround: cut (!), careful clause ordering to control search."
  },
  "constraint-discrete-steps": {
    "title": "Discrete Steps",
    "section": "Representation Constraints",
    "content": "Programs are sequences of discrete statements, not continuous transformations. Between statement 1 and statement 2, nothing happens. This works for most computing but is awkward for physics simulations, animations, or reactive systems—we fake continuity with small time steps."
  },
  "shadowing-detail": {
    "title": "Shadowing Detail",
    "section": "Shadowing",
    "content": "Shadowing doesn't free memory. `let x = Box::new(5); let x = 10;`—the Box isn't dropped at the shadow, it's dropped at scope end. The name→IDENTITY mapping changes, but the old IDENTITY (and its SPACE) persists until normal cleanup. Shadowing is about names, not values."
  },
  "move-detail": {
    "title": "Move Detail",
    "section": "Move",
    "content": "After `let y = x;` (move), x is in a strange state: the name exists, you can shadow it, but you can't use the value. The compiler tracks 'definitely uninitialized' separately from 'never declared.' Move creates a gap between name existence and value existence."
  },
  "heap-detail": {
    "title": "Heap Detail",
    "section": "Heap",
    "content": "Heap is freedom and complexity. Freedom: any lifetime, any sharing pattern. Complexity: who frees? when? Rust's ownership tracks this. GC automates it. C makes it your problem. All because stack's LIFO discipline was too restrictive for real programs."
  },
  "ssa-transform": {
    "title": "SSA Transform",
    "section": "SSA",
    "content": "SSA (Static Single Assignment) transforms `x = 1; x = 2; x = 3;` into `x1 = 1; x2 = 2; x3 = 3;`. Each 'assignment' becomes a new binding. This reveals the truth: we never mutated x—we created new values and reused a name. The representation hid what was really happening."
  },
  "phi-nodes": {
    "title": "Phi Nodes",
    "section": "SSA",
    "content": "When control flow merges (if/else joins), which value does x have? SSA uses φ (phi) nodes: `x3 = φ(x1, x2)` means 'x3 is x1 if we came from the if-branch, x2 if else-branch.' Phi nodes exist because sequential text can't express 'value depends on which TIME path we took.'"
  },
  "rep-term-rewriting": {
    "title": "Term Rewriting",
    "section": "Alternative Representations",
    "content": "Mathematica, Pure: expressions transform until fixed point. Rules like `x+0 → x` apply repeatedly. No mutation—only substitution. 'Execution' is reduction. Different constraint: nontermination risk, strategy matters. Workaround: controlled evaluation (lazy, strict, strategies)."
  },
  "impl-move-subtle": {
    "title": "Why Move Is Subtle",
    "section": "Implications",
    "content": "Move exists because we can't delete. Four distinct states result: (1) name declared, (2) name has value, (3) name moved-from, (4) name re-shadowed. The compiler tracks which. C++ gets this wrong—moved-from objects are 'valid but unspecified.' Rust makes state explicit."
  },
  "impl-shadowing-exists": {
    "title": "Why Shadowing Exists",
    "section": "Implications",
    "content": "Shadowing is 'deletion' within the constraints. We'd rather reclaim the name and memory. We can't, so we overlay a new IDENTITY. Rust allows it; some linters discourage it (confusion risk). Either way, it's a workaround for representation constraints, not a first-class feature."
  },
  "impl-heap-exists": {
    "title": "Why Heap Exists",
    "section": "Implications",
    "content": "Heap is escape from stack discipline. If all lifetimes were nested (caller outlives callee, outer scope outlives inner), stack would suffice. Real programs have shared ownership, independent lifetimes, dynamic sizes. Heap provides flexible SPACE×TIME at the cost of management complexity."
  },
  "impl-forward-only": {
    "title": "Why All Control Flow is Forward",
    "section": "Implications",
    "content": "Loops, branches, exceptions, continuations—all move forward through TIME. There's no 'goto the past.' Loops repeat forward. Exceptions jump forward (up the stack). Continuations capture 'current position' to resume forward. The representation enforces TIME's arrow."
  }
}
